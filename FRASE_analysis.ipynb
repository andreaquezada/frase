{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY93LnmaNRyB9sxIG6W+XC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreaquezada/frase/blob/main/FRASE_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **FRASE assay - Data analysis**\n",
        "\n",
        "The Fluorescence resonance energy transfer (FRET)-based mHTT aggregate seeding assay is a biophysical assay use to follow the aggregation of Huntingtin Exon 1 (HttEx1) during a time course. Besides of using this assay to study HttEx1 aggregation kinetics, it can also be used to assess the effect of inhibitors or the seeding activity of biological Htt samples.\n",
        "\n",
        "It requires the two fluorescently-label proteins (GST-Ex1Q48-CyPet or GST-Ex1Q48-YPet) as decribed in:\n",
        "\n",
        "[A. Ast, A. Buntru, F. Schindler, R. Hasenkopf, A.\n",
        "Schulz, L. Brusendorf, K. Klockmeier, G. Grelle, B.\n",
        "McMahon, H. Niederlechner, I. Jansen, L. Diez, J. Edel,\n",
        "A. Boeddrich, S. A. Franklin, B. Baldo, S. Schnoegl,\n",
        "S. Kunz, B. Purfurst, A. Gaertner, H. H. Kampinga,\n",
        "A. J. Morton,  A. Petersen, J. Kirstein, G. P. Bates, and\n",
        "E. E. Wanker. mhtt seeding activity: A marker of disease progression\n",
        "and neurotoxicity in models of huntington’s disease. Molecular Cell, 71:675–\n",
        "688.e6, 9 2018](https://www.sciencedirect.com/science/article/pii/S1097276518306014?via%3Dihub).\n",
        "\n",
        "This script is designed to analyze FRASE data from this system using a 384-well reading plate and a Tecan reader.\n",
        "\n",
        "It takes two files in .csv format:\n",
        "\n",
        "1) The pippeting scheme, containing the scheme of the 384-well plate.\n",
        "\n",
        "2) The raw data exported form the tecan in a .csv file.\n"
      ],
      "metadata": {
        "id": "JBsTrUNe-LNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Savn84cf-H6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Input files\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import subprocess\n",
        "import csv\n",
        "from scipy.optimize import curve_fit\n",
        "from tabulate import tabulate\n",
        "\n",
        "from sys import version_info\n",
        "python_version = f\"{version_info.major}.{version_info.minor}\"\n",
        "\n",
        "\"\"\"\n",
        "The pipetting scheme and the output sheet need to be exported as csv (comma separated values) files. Change the name of the .csv input file accordingly\n",
        "\"\"\"\n",
        "#@markdown - Specify the csv file name containing the pipetting_scheme\n",
        "pip_file = 'pipetting_scheme.csv' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Specify the csv file name containing the data\n",
        "input_file = 'data_raw.csv' #@param {type:\"string\"}\n",
        "\n",
        "\"\"\"\n",
        "Create a dictionary that contains information about the contents of each well. This will enable the program to recognize and track the substances you placed in each well during your experiment.\n",
        "\"\"\"\n",
        "\n",
        "# Create a dictionary with the pippeting scheme. This command read the CSV file skipping the first row\n",
        "with open(pip_file, 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    next(reader)  # Skip the header row\n",
        "    data = list(reader)\n",
        "\n",
        "# Initialize the dictionary to store field positions\n",
        "my_exp = {}\n",
        "\n",
        "# Iterate through the rows and columns to populate the dictionary\n",
        "for row_index, row in enumerate(data):\n",
        "    for col_index, field in enumerate(row[1:], start=1):  # Start from 1 to skip the first column\n",
        "        row_label = chr(ord('A') + row_index)  # Convert row index to letter\n",
        "        position = f\"{row_label}{col_index}\"\n",
        "\n",
        "        # Check if the field is not empty and not a repeat\n",
        "        if field and field not in my_exp:\n",
        "            # If it's a new field, add it to the dictionary with an empty list\n",
        "            my_exp[field] = []\n",
        "\n",
        "        # If the field is not empty, add the position to its list\n",
        "        if field:\n",
        "            my_exp[field].append(position)\n",
        "\n",
        "# Print the dictionary\n",
        "#for key, value in my_exp.items():\n",
        "#    print(f\"{key}: {value}\")\n",
        "#print(my_exp['CyPet-only'])\n",
        "\n",
        "# Create a new dictionary excluding specified keys - those that are not fret experiments\n",
        "exclude_keys = ['Background', 'CyPet-only', 'YPet-only', 'Blank']\n",
        "my_exp_filtered = {key: value for key, value in my_exp.items() if key not in exclude_keys}\n",
        "\n",
        "# Print the filtered dictionary\n",
        "for key, value in my_exp_filtered.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "\"\"\"\n",
        "Read the file and store the CyPet, yPet and FRET tables in separate csv files (in case you need that)\n",
        "\"\"\"\n",
        "\n",
        "# This awk oneliner creates three separated csv files for CyPet, YPet and FRET\n",
        "awk_command = fr'''awk -F, '/^CyPet/ {{ f = \"CyPet.csv\"; }} /^YPet/ {{ f = \"YPet.csv\"; }} /^FRET/ {{ f = \"FRET.csv\"; }} f {{ print > f; }}' {input_file}'''\n",
        "result = subprocess.check_output(awk_command, shell=True, text=True)\n",
        "\n",
        "\"\"\"\n",
        "Read the tables from the corresponding csv files and store them in pandas dataframes\n",
        "\"\"\"\n",
        "\n",
        "variables = ['CyPet', 'YPet', 'FRET']\n",
        "\n",
        "# Create an empty dictionary to store the raw dataframes\n",
        "raw_df = {}\n",
        "\n",
        "for i in variables:\n",
        "    # Read the file\n",
        "    df = pd.read_csv(f'{i}.csv', skiprows=1)\n",
        "    # Transpose the DataFrame\n",
        "    df = df.transpose()\n",
        "    # Reset the header to the first row and remove the original header\n",
        "    df.columns = df.iloc[0]\n",
        "    df = df[1:]\n",
        "    # Drop columns with NaN (null) header\n",
        "    df = df.dropna(axis=1, how='all')\n",
        "    # Delete Endzeit column in FRET. This must be conditional because CyPet and yPet do not contain that column\n",
        "    if 'Endzeit:' in df.columns:\n",
        "        df.drop('Endzeit:', axis=1, inplace=True)\n",
        "    # Discard rows with null values\n",
        "    df = df.dropna(axis=0)\n",
        "    # Convert all the values in the dataframe to numerical values in case there are some unnoticed strings\n",
        "    df = df.apply(pd.to_numeric, errors='coerce')\n",
        "    # Save the DataFrame as a separate CSV file in a clean format (in case is needed)\n",
        "    df.to_csv(f'{i}_clean.csv', index=False)\n",
        "    # Save the dataframe in the dictionary for later use\n",
        "    raw_df[i] = df\n",
        "\n",
        "# Concatenate all DataFrames in the dictionary\n",
        "raw_df = pd.concat(raw_df.values(), axis=1, keys=raw_df.keys())\n",
        "\n",
        "print(raw_df)\n",
        "\n",
        "\"\"\"\n",
        "Substract the background\n",
        "\"\"\"\n",
        "\n",
        "# Creates an empty dictionary to store the substracted dataframes\n",
        "substracted_df = {}\n",
        "\n",
        "# Extract the well corresponding to the background. This command will take only the first well (element 0) of the Background. Change it to 1 if you want to use the duplicate instead.\n",
        "bg = my_exp['Background'][0]\n",
        "\n",
        "variables = ['CyPet', 'YPet', 'FRET']\n",
        "\n",
        "for i in variables:\n",
        "\n",
        "    # pull the dataframe from the dictionary\n",
        "    my_df = raw_df[f'{i}']\n",
        "\n",
        "    # List the columns of each data frame.\n",
        "    columns = list(my_df.columns.values)\n",
        "\n",
        "    # Create a sublist of the list excluding the columns that correspond to time and Temperature.\n",
        "    data_col = columns[2:]\n",
        "\n",
        "    # Create a list to store the new dataframes\n",
        "    substracted_dfs = []\n",
        "\n",
        "    # Substract the bg from each column.\n",
        "    for j in data_col:\n",
        "        resta = raw_df[i][j] - raw_df[i][bg]\n",
        "        substracted_dfs.append(pd.DataFrame({f'{j}': resta}))\n",
        "\n",
        "    # Concatenate all the DataFrames along the columns (axis=1)\n",
        "    substracted_df[f'{i}'] = pd.concat(substracted_dfs, axis=1)\n",
        "\n",
        "#print(substracted_df)\n",
        "\n",
        "\"\"\"\n",
        "Determine correction factor for CyPet and YPet\n",
        "\"\"\"\n",
        "\n",
        "# Extract the wells corresponding to CyPet and YPet only in my_exp. Assumes there is only one of them per experiment.\n",
        "cypet_only = my_exp['CyPet-only'][0]\n",
        "ypet_only = my_exp['YPet-only'][0]\n",
        "\n",
        "# Gets the correction factor for each fluorophore.\n",
        "cypet_corrfac = np.mean(substracted_df['FRET'][cypet_only]/substracted_df['CyPet'][cypet_only])\n",
        "ypet_corrfac = np.mean(substracted_df['FRET'][ypet_only]/substracted_df['YPet'][ypet_only])\n",
        "\n",
        "#print(cypet_corrfac)\n",
        "#print(ypet_corrfac)\n",
        "\n",
        "\"\"\"\n",
        "Obtaining False FRET\n",
        "\"\"\"\n",
        "\n",
        "# Create an empty dictionary to store the substracted dataframes excluding the background, the cypet-only and the ypet-only wells\n",
        "two_fluo_df = {}\n",
        "\n",
        "# Define the columns to exclude in the new dataframes\n",
        "columns_to_exclude = my_exp['Background'] + my_exp['CyPet-only'] + my_exp['YPet-only']\n",
        "#print(columns_to_exclude)\n",
        "\n",
        "variables = ['CyPet', 'YPet', 'FRET']\n",
        "\n",
        "for l in variables:\n",
        "    two_fluo_df[f'{l}'] = substracted_df[f'{l}'].drop(columns=columns_to_exclude)\n",
        "#print(two_fluo_df['FRET'])\n",
        "\n",
        "# Get False Frate\n",
        "false_fret = two_fluo_df['CyPet']*cypet_corrfac + two_fluo_df['YPet']*ypet_corrfac\n",
        "\n",
        "#print(false_fret)\n",
        "\n",
        "\"\"\"\n",
        "Obtaining Real FRET\n",
        "\"\"\"\n",
        "\n",
        "# Define the data in my_exp that contains actual FRET experiments - with both fluorophores present\n",
        "real_fret = two_fluo_df['FRET'] - false_fret\n",
        "\n",
        "#print(real_fret)\n",
        "\n",
        "\"\"\"\n",
        "Obtaining Normalized FRET\n",
        "\"\"\"\n",
        "\n",
        "# Define the data in my_exp that contains actual FRET experiments - with both fluorophores present\n",
        "norm_fret = real_fret/two_fluo_df['YPet']*100\n",
        "\n",
        "#print(norm_fret)\n",
        "\n",
        "\"\"\"\n",
        "Separate triplicates. Get the mean and the standard deviation.\n",
        "\"\"\"\n",
        "# Creates an empty dictionary to store the data to save in cvs\n",
        "export_data = {}\n",
        "# Creates an empty dataframe to store the data to plot\n",
        "data_list = []\n",
        "\n",
        "# Define the name of each FRASE experiment that was made by triplicates\n",
        "exp_fret = list(my_exp_filtered)\n",
        "\n",
        "# Get the average of each triplicate and the standard deviation.\n",
        "for m in exp_fret:\n",
        "\n",
        "    storem = []\n",
        "    col_to_include = my_exp[f'{m}']\n",
        "\n",
        "    # Get the data for each triplicate\n",
        "    for k in col_to_include:\n",
        "        storem.append(pd.DataFrame({f'{k}':norm_fret[k]}))\n",
        "\n",
        "    # Get the mean for each exp\n",
        "    mean_data = norm_fret[col_to_include].mean(axis=1)\n",
        "    data_list.append(pd.DataFrame({f'{m}':mean_data}))\n",
        "    storem.append(pd.DataFrame({f'mean_{m}':mean_data}))\n",
        "\n",
        "    # Get the standard deviation\n",
        "    sd_data = norm_fret[col_to_include].std(axis=1)\n",
        "    data_list.append(pd.DataFrame({f'std_{m}':sd_data}))\n",
        "    storem.append(pd.DataFrame({f'std_{m}':sd_data}))\n",
        "\n",
        "    # Replace conflicting character /\n",
        "    m = m.replace('/', '_')\n",
        "\n",
        "    # Concatenate the storem list containing information of each triplicate into a dataframe and save it as csv\n",
        "    df = pd.concat(storem, axis=1)\n",
        "    print(df)\n",
        "    df.to_csv(f'data_{m}.csv', index=False)\n",
        "\n",
        "# Concatenate all the means and sd in a dataframe named frase_plot\n",
        "frase_plot = pd.concat(data_list, axis=1)\n",
        "\n",
        "# Obtain time values from first dictionary\n",
        "time = raw_df['FRET']['Zeit [s]']/3600\n",
        "# Create a DataFrame for the 'time' column\n",
        "time_df = pd.DataFrame({'time': time})\n",
        "\n",
        "# Concatenate time_df with frase_plot\n",
        "frase_plot = pd.concat([frase_plot, time_df], axis=1)\n",
        "\n",
        "#print(frase_plot)\n",
        "\n",
        "\"\"\"\n",
        "Fit the curves, obtain t50 and plot the data\n",
        "\"\"\"\n",
        "\n",
        "# Define the name of each FRASE experiment that was made by triplicates\n",
        "exp_fret = list(my_exp_filtered)\n",
        "\n",
        "\n",
        "# Define the generalized Hill equation\n",
        "def hill_equation(x, EC50, Top, Bottom, HillSlope, S):\n",
        "    Denominator = (1 + (2 ** (1/S) - 1) * ((EC50/x) ** HillSlope)) ** S\n",
        "    Numerator = Top - Bottom\n",
        "    return Bottom + (Numerator / Denominator)\n",
        "\n",
        "# Create a new DataFrame for storing t50 values\n",
        "t50_df = pd.DataFrame(columns=['Key', 't50'])\n",
        "\n",
        "# Create a dictionary to store the fitted curves\n",
        "fitted_curves_dict = {}\n",
        "\n",
        "# Read time and fret for each mean curve and assign variables x and y\n",
        "for l in exp_fret:\n",
        "    x = frase_plot['time']\n",
        "    y = frase_plot[l]\n",
        "\n",
        "    # Initial parameter guesses (you might need to adjust these based on your data)\n",
        "    initial_params = [50, 100, 0, 1, 2]\n",
        "\n",
        "    # Fit the data to the hill equation\n",
        "    params, _ = curve_fit(hill_equation, x, y, p0=initial_params)\n",
        "\n",
        "    # Extract the t50 parameter\n",
        "    t50_value = params[0]\n",
        "\n",
        "    # Append the key and t50 value to the new DataFrame\n",
        "    t50_df = pd.concat([t50_df, pd.DataFrame({'Key': [l], 't50': [t50_value]})], ignore_index=True)\n",
        "\n",
        "    # Generate the fitted curve using the fitted parameters\n",
        "    fitted_curve = hill_equation(x, *params)\n",
        "\n",
        "    # Store the fitted curve in the dictionary\n",
        "    fitted_curves_dict[l] = fitted_curve\n",
        "\n",
        "# Print the resulting t50 DataFrame and fitted curves\n",
        "t50_df.to_csv('t50.csv', index=False)\n",
        "print(tabulate(t50_df, headers='keys', tablefmt='psql'))\n",
        "print(type(t50_df))\n",
        "#print(fitted_curves_dict)\n",
        "\n",
        "\"\"\"\n",
        "Plot the data\n",
        "\"\"\"\n",
        "# Define the colormap\n",
        "\n",
        "# Define a custom palette with MDC colors Blue, Dark Blue, Dark Red, Dark Teal, Light Blue, Light Red, Light Teal, Red, Teal\n",
        "custom_palette = ['#1e3791', '#141955', '#780050', '#005055', '#87aadc', '#faafaf', '#9bd7d2', '#eb2d4b', '#00ac8c']\n",
        "custom_palette = ['#1e3791', '#00ac8c']\n",
        "\n",
        "# Check if custom_palette is defined\n",
        "use_custom_palette = 'custom_palette' in locals()\n",
        "\n",
        "# ... or used one from the system\n",
        "#palette = cm.viridis\n",
        "#palette = cm.gist_stern\n",
        "#palette = cm.brg\n",
        "#palette = cm.jet\n",
        "#palette = cm.hot\n",
        "\n",
        "\n",
        "#for column in filtered_exp:\n",
        "for i, column in enumerate(exp_fret):\n",
        "    if use_custom_palette:\n",
        "        color = custom_palette[i % len(custom_palette)]  # Cycle through custom colors\n",
        "    else:\n",
        "        color = cm.viridis(i / len(exp_fret))  # Use viridis colormap\n",
        "\n",
        "    plt.errorbar(frase_plot['time'], frase_plot[f'{column}'], yerr=frase_plot[f'std_{column}'], label = column, capsize=3, fmt='.', linestyle='None', color=color)\n",
        "    plt.plot(frase_plot['time'], fitted_curves_dict[f'{column}'], color=color)\n",
        "\n",
        "plt.xlabel('Time (h)', fontweight='bold', size=12)\n",
        "plt.ylabel('FRET efficiency (%)', fontweight='bold', size=12)\n",
        "plt.yticks(fontweight='bold', size=10)\n",
        "plt.xticks(fontweight='bold', size=10)\n",
        "plt.legend(loc='center', bbox_to_anchor=(1.15, 0.5))\n",
        "\n",
        "plt.savefig('frase.svg')\n",
        "plt.savefig('frase.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZSSzCq9k-IdP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}